import streamlit as st
from google import genai
from google.genai import types
import os
from typing import TypedDict
from langgraph.graph import StateGraph, END

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Gemini æ™ºèƒ½ä½“å·¥å‚",
    page_icon="ğŸ§ ",
    layout="wide"
)

st.title("ğŸ§  Gemini æ·±åº¦æ€è€ƒ Agent")
st.caption("é›†æˆ LangGraphï¼šå†™ä½œ -> åæ€ -> ä¿®æ­£ è‡ªåŠ¨åŒ–é—­ç¯")

# --- 2. ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.header(" æ§åˆ¶å°")
    # API Key ç®¡ç†
    default_key = os.environ.get("GEMINI_API_KEY", "")
    # å¦‚æœ secrets é‡Œæœ‰ï¼Œä¼˜å…ˆç”¨ secrets
    if "GEMINI_API_KEY" in st.secrets:
        default_key = st.secrets["GEMINI_API_KEY"]
        
    api_key = st.text_input("Gemini API Key", value=default_key, type="password")
    
    st.divider()
    model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", ["gemini-2.5-flash", "gemini-2.5-flash-lite"], index=0)
    max_revisions = st.slider("æœ€å¤§åæ€æ¬¡æ•°", 1, 5, 2, help="æ‰¹è¯„å®¶æœ€å¤šå¯ä»¥è®©ä½œå®¶é‡å†™å‡ æ¬¡ï¼Ÿ")
    
    with st.expander(" è§’è‰²è®¾å®š (é«˜çº§)"):
        writer_instruction = st.text_area("ä½œå®¶è®¾å®š", value="ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„æŠ€æœ¯ä½œå®¶ï¼Œå–„äºä½¿ç”¨ç®€å•çš„è¯­è¨€è§£é‡Šå¤æ‚çš„æ¦‚å¿µã€‚")
        critic_instruction = st.text_area("æ‰¹è¯„å®¶è®¾å®š", value="ä½ æ˜¯ä¸€ä¸ªå¹æ¯›æ±‚ç–µçš„å®¡æ ¸å‘˜ï¼Œä¸ä»…æ£€æŸ¥äº‹å®é”™è¯¯ï¼Œè¿˜å…³æ³¨é€»è¾‘è¿è´¯æ€§å’Œè¯­æ°”ã€‚")
    
    if st.button(" æ¸…ç©ºå¯¹è¯", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- 3. åˆå§‹åŒ– Client ---
if not api_key:
    st.warning("è¯·å…ˆé…ç½® API Key")
    st.stop()

client = genai.Client(api_key=api_key)

# --- 4. å®šä¹‰ LangGraph é€»è¾‘ (Day 24 çš„æ ¸å¿ƒ) ---

# å®šä¹‰çŠ¶æ€
class AgentState(TypedDict):
    task: str
    draft: str
    critique: str
    revision_count: int
    content_history: list # ç”¨æ¥è®°å½•ä¸­é—´è¿‡ç¨‹ï¼Œæ–¹ä¾¿åœ¨ç½‘é¡µå±•ç¤º
    writer_instruction: str
    critic_instruction: str

# å®šä¹‰èŠ‚ç‚¹ Aï¼šä½œå®¶
def writer_node(state: AgentState):
    task = state['task']
    critique = state.get('critique', "")
    count = state.get('revision_count', 0)
    history = state.get('content_history', [])
    writer_instruction = state.get('writer_instruction', "")
    
    if count == 0:
        prompt = f"""
        ã€ä½ çš„è§’è‰²è®¾å®šã€‘ï¼š{writer_instruction}
        ã€ä»»åŠ¡ã€‘ï¼šè¯·ç®€çŸ­åœ°å†™ä¸€æ®µå…³äº '{task}' çš„ä»‹ç»ã€‚
        """
        step_name = " åˆç¨¿åˆ›ä½œä¸­..."
    else:
        prompt = f"""
        ã€ä½ çš„è§’è‰²è®¾å®šã€‘ï¼š{writer_instruction}
        åŸç¨¿ï¼š{state['draft']}
        æ‰¹è¯„æ„è§ï¼š{critique}
        ä»»åŠ¡ï¼šè¯·æ ¹æ®æ‰¹è¯„æ„è§ï¼Œé‡å†™è¿™æ®µå…³äº '{task}' çš„ä»‹ç»ã€‚
        """
        step_name = f" ç¬¬ {count+1} æ¬¡ä¿®æ”¹ä¸­..."
        
    response = client.models.generate_content(
        model=model_name, contents=prompt
    )
    
    # è®°å½•è¿‡ç¨‹
    history.append(f"**{step_name}**\n\n{response.text}")
    
    return {
        "draft": response.text, 
        "revision_count": count + 1,
        "content_history": history
    }

# å®šä¹‰èŠ‚ç‚¹ Bï¼šæ‰¹è¯„å®¶
def critic_node(state: AgentState):
    draft = state['draft']
    history = state.get('content_history', [])
    critic_instruction = state.get('critic_instruction', "")
    
    prompt = f"""
    ã€ä½ çš„è§’è‰²è®¾å®šã€‘ï¼š{critic_instruction}
    
    è¯·å®¡æ ¸ä»¥ä¸‹è‰ç¨¿ï¼š
    {draft}
    
    å¦‚æœè‰ç¨¿å†™å¾—éå¸¸å®Œç¾ä¸”å­—æ•°è¶…è¿‡ 50 å­—ï¼Œè¯·å›å¤ 'PASS'ã€‚
    å¦‚æœè‰ç¨¿å¤ªçŸ­æˆ–è€…æœ‰é”™è¯¯ï¼Œè¯·ç»™å‡ºç®€çŸ­çš„ä¿®æ”¹å»ºè®®ï¼ˆä¸è¦è¶…è¿‡ 20 å­—ï¼‰ã€‚
    """
    
    response = client.models.generate_content(
        model=model_name, contents=prompt
    )
    
    history.append(f"**ğŸ§ æ‰¹è¯„å®¶å®¡æ ¸:** {response.text}")
    
    return {
        "critique": response.text,
        "content_history": history
    }

# å®šä¹‰è·¯ç”±é€»è¾‘
def should_continue(state: AgentState):
    critique = state['critique']
    count = state['revision_count']
    
    # è¿™é‡Œç”¨ä¾§è¾¹æ çš„ max_revisions å˜é‡
    if "PASS" in critique or count >= max_revisions:
        return END
    return "writer"

# æ„å»ºå›¾ (æ”¾åˆ°å‡½æ•°é‡Œï¼Œæ¯æ¬¡è°ƒç”¨æ—¶æ„å»º)
def get_graph():
    workflow = StateGraph(AgentState)
    workflow.add_node("writer", writer_node)
    workflow.add_node("critic", critic_node)
    workflow.set_entry_point("writer")
    workflow.add_edge("writer", "critic")
    workflow.add_conditional_edges("critic", should_continue, {END: END, "writer": "writer"})
    return workflow.compile()

# --- 5. èŠå¤©ç•Œé¢é€»è¾‘ ---

if "messages" not in st.session_state:
    st.session_state.messages = []

# æ¸²æŸ“å†å²
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        # å¦‚æœæœ‰ä¸­é—´æ€è€ƒè¿‡ç¨‹ï¼Œç”¨æŠ˜å é¢æ¿æ˜¾ç¤º
        if "thoughts" in msg:
            with st.expander("æŸ¥çœ‹ AI çš„æ€è€ƒ/åæ€è¿‡ç¨‹"):
                for step in msg["thoughts"]:
                    st.markdown(step)
                    st.divider()

# å¤„ç†è¾“å…¥
if prompt := st.chat_input("è¾“å…¥ä¸€ä¸ªä¸»é¢˜ï¼ˆä¾‹å¦‚ï¼šPythonè¯­è¨€ã€é‡å­åŠ›å­¦...ï¼‰"):
    # 1. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. è¿è¡Œ LangGraph
    with st.chat_message("assistant"):
        status_container = st.status("ğŸ§  AI æ­£åœ¨è¿›è¡Œæ·±åº¦æ€è€ƒå¾ªç¯...", expanded=True)
        
        try:
            app = get_graph()
            inputs = {
                "task": prompt, 
                "revision_count": 0, 
                "content_history": [],
                "writer_instruction": writer_instruction,
                "critic_instruction": critic_instruction
            }
            
            # è¿è¡Œå›¾ï¼Œæ‹¿åˆ°æœ€ç»ˆçŠ¶æ€
            final_state = app.invoke(inputs)
            
            # æ›´æ–°çŠ¶æ€å®¹å™¨
            status_container.update(label=" æ€è€ƒå®Œæˆï¼", state="complete", expanded=False)
            
            # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
            final_response = final_state['draft']
            st.markdown(final_response)
            
            # æ‹¿åˆ°ä¸­é—´è¿‡ç¨‹å†å²
            thoughts = final_state['content_history']
            
            # åœ¨æŠ˜å é¢æ¿é‡Œå±•ç¤ºä¸­é—´è¿‡ç¨‹ï¼ˆè®©ç”¨æˆ·çœ‹åˆ°Writerå’ŒCriticçš„åµæ¶è¿‡ç¨‹ï¼‰
            with st.expander("ç‚¹å‡»æŸ¥çœ‹ ä½œå®¶ vs æ‰¹è¯„å®¶ çš„åšå¼ˆè¿‡ç¨‹"):
                for step in thoughts:
                    st.markdown(step)
                    st.divider()

            # ä¿å­˜åˆ°å†å²
            st.session_state.messages.append({
                "role": "assistant", 
                "content": final_response,
                "thoughts": thoughts # æŠŠæ€è€ƒè¿‡ç¨‹ä¹Ÿå­˜ä¸‹æ¥
            })
            
        except Exception as e:
            status_container.update(label=" å‡ºé”™äº†", state="error")
            st.error(f"è¿è¡Œå¤±è´¥: {e}")
